# Environment Configuration for Kotaemon MCP Server
# Copy this file to .env and configure your settings

# =============================================================================
# LLM CONFIGURATION
# =============================================================================

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_CHAT_MODEL=gpt-4o-mini
OPENAI_EMBEDDINGS_MODEL=text-embedding-3-large

# Azure OpenAI Configuration (alternative to OpenAI)
# AZURE_OPENAI_API_KEY=your_azure_openai_key
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
# AZURE_OPENAI_CHAT_DEPLOYMENT=your-chat-deployment
# AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT=your-embeddings-deployment
# OPENAI_API_VERSION=2024-02-15-preview

# Anthropic Configuration
# ANTHROPIC_API_KEY=your_anthropic_api_key

# Google Configuration
# GOOGLE_API_KEY=your_google_api_key

# Cohere Configuration
# COHERE_API_KEY=your_cohere_api_key

# Mistral Configuration
# MISTRAL_API_KEY=your_mistral_api_key

# Groq Configuration
# GROQ_API_KEY=your_groq_api_key

# =============================================================================
# LOCAL MODEL CONFIGURATION (OLLAMA)
# =============================================================================

# Enable local models with Ollama
# LOCAL_MODEL=llama3.1:8b
# LOCAL_MODEL_EMBEDDINGS=nomic-embed-text
# KH_OLLAMA_URL=http://localhost:11434/v1/

# =============================================================================
# GRAPHRAG CONFIGURATION
# =============================================================================

# Enable/disable GraphRAG features
USE_NANO_GRAPHRAG=false
USE_LIGHTRAG=false
USE_MS_GRAPHRAG=false

# Microsoft GraphRAG (requires OpenAI API key)
# GRAPHRAG_API_KEY=your_openai_api_key
# USE_CUSTOMIZED_GRAPHRAG_SETTING=false

# =============================================================================
# STORAGE CONFIGURATION
# =============================================================================

# Data directory for kotaemon
KOTAEMON_DATA_DIR=./ktem_app_data

# Vector store configuration
# Supported: chromadb, lancedb, milvus, qdrant
KH_VECTORSTORE_TYPE=chromadb

# Document store configuration  
# Supported: simple_file, elasticsearch, lancedb
KH_DOCSTORE_TYPE=lancedb

# =============================================================================
# DOCUMENT PROCESSING CONFIGURATION
# =============================================================================

# Multimodal document processing
# USE_MULTIMODAL=false

# Azure Document Intelligence
# AZURE_DOC_INTELLIGENCE_KEY=your_azure_doc_intelligence_key
# AZURE_DOC_INTELLIGENCE_ENDPOINT=your_azure_doc_intelligence_endpoint

# Adobe PDF Extract
# ADOBE_CLIENT_ID=your_adobe_client_id
# ADOBE_CLIENT_SECRET=your_adobe_client_secret

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================

# Logging level (DEBUG, INFO, WARNING, ERROR)
KOTAEMON_LOG_LEVEL=INFO

# Demo mode (disables certain features)
KH_DEMO_MODE=false

# Enable first-time setup
KH_ENABLE_FIRST_SETUP=true

# Features
KH_FEATURE_CHAT_SUGGESTION=false
KH_FEATURE_USER_MANAGEMENT=false

# =============================================================================
# PERFORMANCE CONFIGURATION
# =============================================================================

# Indexing batch size
INDEX_BATCHSIZE=10

# Maximum context length for LLMs
MAX_CONTEXT_LENGTH=32000

# Chunk size for document processing
DEFAULT_CHUNK_SIZE=1000
DEFAULT_CHUNK_OVERLAP=200

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

# Secret key for sessions (generate a random string)
SECRET_KEY=your-secret-key-here

# User management (if enabled)
# KH_FEATURE_USER_MANAGEMENT_ADMIN=admin
# KH_FEATURE_USER_MANAGEMENT_PASSWORD=admin

# =============================================================================
# OPTIONAL SERVICES
# =============================================================================

# Elasticsearch (if using Elasticsearch document store)
# ELASTICSEARCH_HOST=localhost
# ELASTICSEARCH_PORT=9200
# ELASTICSEARCH_USER=
# ELASTICSEARCH_PASSWORD=

# Milvus (if using Milvus vector store)
# MILVUS_HOST=localhost
# MILVUS_PORT=19530
# MILVUS_USER=
# MILVUS_PASSWORD=

# Qdrant (if using Qdrant vector store)
# QDRANT_HOST=localhost
# QDRANT_PORT=6333
# QDRANT_API_KEY=

# =============================================================================
# DEVELOPMENT CONFIGURATION
# =============================================================================

# Enable debug mode
# DEBUG=false

# Gradio configuration (for web UI)
# KH_GRADIO_SHARE=false
# GRADIO_SERVER_PORT=7860

# =============================================================================
# EXAMPLES AND NOTES
# =============================================================================

# Example OpenAI setup:
# OPENAI_API_KEY=sk-...
# OPENAI_CHAT_MODEL=gpt-4o-mini
# OPENAI_EMBEDDINGS_MODEL=text-embedding-3-large

# Example Ollama setup:
# LOCAL_MODEL=llama3.1:8b
# LOCAL_MODEL_EMBEDDINGS=nomic-embed-text
# KH_OLLAMA_URL=http://localhost:11434/v1/

# Example Azure setup:
# AZURE_OPENAI_API_KEY=...
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
# AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o-mini
# AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT=text-embedding-3-large

# To use this file:
# 1. Copy this file to .env
# 2. Uncomment and configure the variables you need
# 3. Restart the MCP server
